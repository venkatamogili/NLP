{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatamogili/NLP/blob/main/1_Bow_vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUoJOk7koMuY",
        "outputId": "a454a18a-7d85-4c7d-e5bd-1e0a2d95346e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['adore' 'learning' 'love' 'machine']\n",
            "BOW matrix:\n",
            " [[0 1 1 1]\n",
            " [1 1 0 1]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Example 1: Synonyms (no shared tokens → zero overlap)\n",
        "docs = [\n",
        "    \"I love machine learning\",\n",
        "    \"I adore machine learning\"\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(docs)\n",
        "\n",
        "print(\"Features:\", vectorizer.get_feature_names_out())\n",
        "print(\"BOW matrix:\\n\", bow.toarray())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Example 2: Morphological variants inflate vocab\n",
        "docs = [\n",
        "    \"cats are cute\",\n",
        "    \"cat is cute\",\n",
        "    \"cat sitting on the mat\"\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(docs)\n",
        "\n",
        "print(\"Features:\", vectorizer.get_feature_names_out())\n",
        "print(\"BOW matrix:\\n\", bow.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWEBc9kjonI6",
        "outputId": "e142e6b6-dd50-4b77-ddff-851497327b34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['are' 'cat' 'cats' 'cute' 'is' 'mat' 'on' 'sitting' 'the']\n",
            "BOW matrix:\n",
            " [[1 0 1 1 0 0 0 0 0]\n",
            " [0 1 0 1 1 0 0 0 0]\n",
            " [0 1 0 0 0 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Example 4: Vocabulary explosion with more docs\n",
        "docs = [\n",
        "    \"data science is fun\",\n",
        "    \"deep learning builds on data science\",\n",
        "    \"natural language processing is part of AI\",\n",
        "    \"AI and ML are transforming industry\"\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(docs)\n",
        "\n",
        "print(\"Features:\", vectorizer.get_feature_names_out())\n",
        "print(\"BOW matrix:\\n\", bow.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ8iPn9covqk",
        "outputId": "5e3aa920-78a2-451c-d18b-ea8a4e2fa5aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['ai' 'and' 'are' 'builds' 'data' 'deep' 'fun' 'industry' 'is' 'language'\n",
            " 'learning' 'ml' 'natural' 'of' 'on' 'part' 'processing' 'science'\n",
            " 'transforming']\n",
            "BOW matrix:\n",
            " [[0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0]\n",
            " [1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0]\n",
            " [1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "docs = [\n",
        "    \"I love machine learning\",\n",
        "    \"I adore machine learning\",\n",
        "    \"Cats are cute and playful\",\n",
        "    \"The cat is very cute and playful\",\n",
        "    \"Natural language processing is fascinating\",\n",
        "    \"Processing natural languages is fascinating\",\n",
        "    \"Deep learning builds on neural networks\",\n",
        "    \"Neural networks underpin deep learning\",\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"A fast dark‑colored fox leaps above a sleepy canine\"\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(docs)\n",
        "\n",
        "print(\"Features:\", vectorizer.get_feature_names_out())\n",
        "print(\"BOW matrix:\\n\", bow.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Nw7ap9o58I",
        "outputId": "471dfb26-b96c-4174-c78c-780aa212cb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['above' 'adore' 'and' 'are' 'brown' 'builds' 'canine' 'cat' 'cats'\n",
            " 'colored' 'cute' 'dark' 'deep' 'dog' 'fascinating' 'fast' 'fox' 'is'\n",
            " 'jumps' 'language' 'languages' 'lazy' 'leaps' 'learning' 'love' 'machine'\n",
            " 'natural' 'networks' 'neural' 'on' 'over' 'playful' 'processing' 'quick'\n",
            " 'sleepy' 'the' 'underpin' 'very']\n",
            "BOW matrix:\n",
            " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0]\n",
            " [0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            "  0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
            "  0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
            "  0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
            "  0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0\n",
            "  0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0\n",
            "  1 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 2\n",
            "  0 0]\n",
            " [1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# 10 “large” example sentences\n",
        "docs = [\n",
        "    \"Advances in natural language processing have revolutionized how machines interpret and generate human language, enabling applications such as chatbots, machine translation, and sentiment analysis at scale.\",\n",
        "    \"The integration of machine learning algorithms into healthcare diagnostics has significantly improved the accuracy of disease detection, personalized treatment recommendations, and patient monitoring systems.\",\n",
        "    \"Modern deep learning architectures, including convolutional neural networks and recurrent neural networks, form the backbone of state-of-the-art computer vision and sequential data processing tasks.\",\n",
        "    \"Generative adversarial networks have demonstrated remarkable capabilities in synthesizing realistic images, videos, and audio, opening new frontiers in creative AI and data augmentation techniques.\",\n",
        "    \"Reinforcement learning methods empower agents to learn optimal behaviors through trial and error, achieving superhuman performance in complex games like Go and advanced robotics control tasks.\",\n",
        "    \"Efficient deployment of large language models on cloud platforms requires careful consideration of inference latency, cost optimization, and scalable serving architectures to meet real-time application demands.\",\n",
        "    \"Transfer learning and fine-tuning pretrained transformer-based models on domain-specific corpora allow practitioners to achieve high performance with limited labeled data and computational resources.\",\n",
        "    \"Attention mechanisms have become a fundamental component of modern sequence-to-sequence models, enabling the network to selectively focus on relevant parts of the input when generating each token of the output.\",\n",
        "    \"The responsible use of AI technologies necessitates rigorous evaluation of fairness, accountability, transparency, and ethics to mitigate biases and ensure trustworthiness in automated decision-making systems.\",\n",
        "    \"Multimodal learning approaches that combine text, image, and audio data streams offer a comprehensive understanding of complex phenomena, paving the way for more versatile and robust AI systems.\"\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(docs)\n",
        "\n",
        "print(\"Features:\", vectorizer.get_feature_names_out())\n",
        "print(\"BOW matrix:\\n\", bow.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-opQ372tf6W",
        "outputId": "cadfa0f3-2539-4776-d805-968450c1d0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['accountability' 'accuracy' 'achieve' 'achieving' 'advanced' 'advances'\n",
            " 'adversarial' 'agents' 'ai' 'algorithms' 'allow' 'analysis' 'and'\n",
            " 'application' 'applications' 'approaches' 'architectures' 'art' 'as' 'at'\n",
            " 'attention' 'audio' 'augmentation' 'automated' 'backbone' 'based'\n",
            " 'become' 'behaviors' 'biases' 'capabilities' 'careful' 'chatbots' 'cloud'\n",
            " 'combine' 'complex' 'component' 'comprehensive' 'computational'\n",
            " 'computer' 'consideration' 'control' 'convolutional' 'corpora' 'cost'\n",
            " 'creative' 'data' 'decision' 'deep' 'demands' 'demonstrated' 'deployment'\n",
            " 'detection' 'diagnostics' 'disease' 'domain' 'each' 'efficient' 'empower'\n",
            " 'enabling' 'ensure' 'error' 'ethics' 'evaluation' 'fairness' 'fine'\n",
            " 'focus' 'for' 'form' 'frontiers' 'fundamental' 'games' 'generate'\n",
            " 'generating' 'generative' 'go' 'has' 'have' 'healthcare' 'high' 'how'\n",
            " 'human' 'image' 'images' 'improved' 'in' 'including' 'inference' 'input'\n",
            " 'integration' 'interpret' 'into' 'labeled' 'language' 'large' 'latency'\n",
            " 'learn' 'learning' 'like' 'limited' 'machine' 'machines' 'making'\n",
            " 'mechanisms' 'meet' 'methods' 'mitigate' 'models' 'modern' 'monitoring'\n",
            " 'more' 'multimodal' 'natural' 'necessitates' 'network' 'networks'\n",
            " 'neural' 'new' 'of' 'offer' 'on' 'opening' 'optimal' 'optimization'\n",
            " 'output' 'parts' 'patient' 'paving' 'performance' 'personalized'\n",
            " 'phenomena' 'platforms' 'practitioners' 'pretrained' 'processing' 'real'\n",
            " 'realistic' 'recommendations' 'recurrent' 'reinforcement' 'relevant'\n",
            " 'remarkable' 'requires' 'resources' 'responsible' 'revolutionized'\n",
            " 'rigorous' 'robotics' 'robust' 'scalable' 'scale' 'selectively'\n",
            " 'sentiment' 'sequence' 'sequential' 'serving' 'significantly' 'specific'\n",
            " 'state' 'streams' 'such' 'superhuman' 'synthesizing' 'systems' 'tasks'\n",
            " 'techniques' 'technologies' 'text' 'that' 'the' 'through' 'time' 'to'\n",
            " 'token' 'transfer' 'transformer' 'translation' 'transparency' 'treatment'\n",
            " 'trial' 'trustworthiness' 'tuning' 'understanding' 'use' 'versatile'\n",
            " 'videos' 'vision' 'way' 'when' 'with']\n",
            "BOW matrix:\n",
            " [[0 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 1 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 1 0 0]]\n"
          ]
        }
      ]
    }
  ]
}